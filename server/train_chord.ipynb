{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '/kaggle/input/major-vs-minor-guitar-chords/shords_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchaudio\n",
    "import IPython\n",
    "from scipy import signal\n",
    "from scipy.io.wavfile import read as read_wav\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_filenames = os.listdir('/kaggle/input/major-vs-minor-guitar-chords/shords_dataset/major')\n",
    "minor_filenames = os.listdir('/kaggle/input/major-vs-minor-guitar-chords/shords_dataset/minor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio(path):\n",
    "    sampling_rate, data=read_wav(path)\n",
    "    return IPython.display.Audio(path, rate = sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_spectrogram(path):\n",
    "    sample_rate, data=read_wav(path)\n",
    "    #stereo to mono\n",
    "    mono = (data[:,0] + data[:,1]) / 2 \n",
    "    plt.specgram(mono, Fs=sample_rate)\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, dir_path, major_filenames, minor_filenames, cut = 30000):\n",
    "        self.major_filenames = major_filenames\n",
    "        self.minor_filenames = minor_filenames\n",
    "        self.dir_path = dir_path\n",
    "        self.cut = cut\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.major_filenames) + len(self.minor_filenames)      \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        is_major =  idx < len(self.major_filenames)\n",
    "        path = self.dir_path + ('major/' + self.major_filenames[idx] if is_major else 'minor/' + self.minor_filenames[idx - len(self.major_filenames)])\n",
    "        waveform , _ = torchaudio.load(path)\n",
    "        waveform = waveform[:,:self.cut].mean(axis = 0)\n",
    "        specgram = torchaudio.transforms.Spectrogram()(waveform)\n",
    "        sp_shape = specgram.shape\n",
    "        return specgram.reshape(1, sp_shape[0], sp_shape[1]), is_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = Dataset(\n",
    "    dir_path, major_filenames, minor_filenames\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                        batch_size = 32,\n",
    "                                        shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=3, padding = 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.bn = nn.BatchNorm2d(output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):    \n",
    "        out = self.conv(x)\n",
    "        out = self.pool(out)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, dims, num_classes = 2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for i in range(1, len(dims)):\n",
    "            self.layers.append(CNNBlock(input_dim = dims[i - 1], output_dim = dims[i]))\n",
    "        \n",
    "        self.gap = nn.AvgPool2d(kernel_size = (25, 18))\n",
    "        self.fc = nn.Linear(dims[-1], num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):     \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        out = self.gap(x)\n",
    "        shape = out.shape\n",
    "        out = out.reshape(shape[0], shape[1])\n",
    "        out = self.fc(out)\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN([1,32,64,128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for idx, (data, label) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device).float()\n",
    "        label = label.to(device).float()\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred, label.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if idx % 100 == 0:\n",
    "            y_hat = torch.argmax(pred, dim = 1)\n",
    "            correct = (y_hat == label).sum()\n",
    "            print(f\"Epoch {epoch} {idx}/{len(train_dataloader)} Loss = {loss.data:.03f}, acc = {correct / label.shape[0]:.02f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/kaggle/working/guitar_chord_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
